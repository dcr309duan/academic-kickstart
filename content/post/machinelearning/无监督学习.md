---
title: "无监督学习"
date: 2019-05-23T11:16:40+08:00
draft: false
math: true
# Tags and categories
# For example, use `tags = []` for no tags, or the form `tags = ["A Tag", "Another Tag"]` for one or more tags.
tags: ['Machine Learning', 'Unsupervised Learning']
categories: ['Machine Learning']
# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder. 
image:
  # Caption (optional)
  caption: ''

  # Focal point (optional)
  # Options: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight
  focal_point: ''
---

# Unsupervised Learning

* Supervised learning: given a labeled training set to fit a hypothesis to it.
* Unsupervised learning: given a unlabeled set to an algorithm and ask the algorithm find some structure in the data.
  * Clustering algorithm

## Clustering

We are given an unlabeled data set and we would like to have an algorithm automatically group the data into coherent subsets or into coherent clusters for us.

### K-Means Algorithm

1. Randomly initialize two (the number of groups you want your data to be grouped to) points, called cluster centroids.

2. Iteration

   1. cluster assignment step

      * assign each point to one of the two groups.

        ![image-20190515144556808](https://markdown-1252040768.cos.ap-beijing.myqcloud.com/2019-05-23-032105.png)

   2. move centroid step

      * Move to average position of every group

Formal illustration:

* Input:
  * $K$ (number of clusters)
  * Training set $\{x^{(1)}, x^{(2)}, \dots, x^{(m)}\}$
  * $x^{(i)} \in R^n$

1. Randomly initialize $K$ cluster centroids $\mu_1, \mu_2, \dots, \mu_K \in R^n$

2. Repeat

   1. for $i=1$ to $m$

      $c^{(i)}:=$ index (from 1 to $K$) of cluster centroid closest ($||x^{(i)}-\mu_k||$) to $x^{(i)}$

   2. for $k=1$ to $K$

      $\mu_k:=$ average (mean) of points assigned to cluster $k$

An K-means application:

![image-20190523154319441](https://markdown-1252040768.cos.ap-beijing.myqcloud.com/2019-05-23-074319.png)

### Optimization Objective

#### Why we need an optimization objective

1. An objective function can help us to determine that the algorithm work correctly (debug).
2. Help us to find better clissfication.

#### Defination

* $c^{(i)}$: index of cluster ($1, 2, \dots, K$) to which example $x^{(i)}$ is currently assigned.
* $\mu_k$: cluster centroid $k$ ($\mu_k \in R^n$)
* $\mu_{c^{(i)}}$: cluster centroid of cluster to which example $x^{(i)}$ has been assigned.

#### Optimization Objective

$$
J(c^{(1)}, \dots, c^{(m)}, \mu_1, \dots, \mu_k) = \frac{1}{m}\sum_{i=1}^m ||x^{(i)} - \mu_{c^{(i)}}||^2
$$

We can find that in the K-means algorithm, we find the $c^{(i)}$ which is the index of cluster centroid closest to $x^{(i)}$, this is equivalent to $\min J()$ , while holding $\mu_i$ fixed.

### Random Initialization

* Should have $K < m$
* Randomly pick $K$ training examples
* Set $\mu_1, \dots, \mu_K$ equal to these $K$ examples.

#### Local optima

Different initial points can lead to different result, may lead to local optima. For example:

![image-20190523223205799](https://markdown-1252040768.cos.ap-beijing.myqcloud.com/2019-05-23-143206.png)

The upper one is great, but the below two are local optimas.

We sould try different initial situation.

We can try many times of initialization, and calculate the cost function.